pp <- mknEvaluate(mkn, test, sents = NULL, directories)
nGramTypes <- list('Quadgram', 'Trigram', 'Bigram', 'Unigram')
model <- loadModel(mkn)
testData <- loadTestData(test, sents)
nGramTypes <- list('Quadgram', 'Trigram', 'Bigram', 'Unigram')
model <- loadModel(mkn)
testData <- loadTestData(test, sents)
document <- readFile(test)
document <- readFile(test)
testData <- list(
document = document,
sents = length(document),
tokens = sum(ntoken(dfm)),
types = length(featnames(dfm)),
size = object.size(document)
)
testData <- loadTestData(test, sents)
message(paste('...loading test data'))
document <- readFile(test)
if (!(is.null(sents))) {
document <- sampleData(document, numChunks = sents, chunkSize = 1, format = 'v')
}
dfm <- quanteda::dfm(document, what = 'fasterword', remove = bos, ngrams = 1)
testData <- list(
document = document,
sents = length(document),
tokens = sum(ntoken(dfm)),
types = length(featnames(dfm)),
size = object.size(document)
)
return(testData)
message(paste('...loading test data'))
document <- readFile(test)
if (!(is.null(sents))) {
document <- sampleData(document, numChunks = sents, chunkSize = 1, format = 'v')
}
dfm <- quanteda::dfm(document, what = 'fasterword', remove = bos, ngrams = 1)
testData <- list(
document = document,
sents = length(document),
tokens = sum(ntoken(dfm)),
types = length(featnames(dfm)),
size = object.size(document)
)
message(paste('...loading test data'))
document <- readFile(test)
if (!(is.null(sents))) {
document <- sampleData(document, numChunks = sents, chunkSize = 1, format = 'v')
}
dfm <- quanteda::dfm(document, what = 'fasterword', remove = bos, ngrams = 1)
quanteda::tokensize(document, what = 'fasterword', remove = bos, ngrams = 1)
quanteda::tokenize(document, what = 'fasterword', remove = bos, ngrams = 1)
quanteda::dfm(document, remove = bos, ngrams = 1)
document <- readFile(test)
dfm <- quanteda::dfm(document, what = 'fasterword', remove = bos, ngrams = 1)
testData <- list(
document = document,
sents = length(document),
tokens = sum(ntoken(dfm)),
types = length(featnames(dfm)),
size = object.size(document)
)
test
testData <- loadTestData(test, sents)
document <- readFile(test)
bos = '<s>'
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM0A.mknEvaluate.R')
pp <- mknEvaluate(mkn, test, sents = NULL, directories = directories)
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM00.mknPipeline.R')
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM0A.mknEvaluate.R')
training <- corpora$training$alpha
test <- corpora$training$alpha
mkn <- lm$mkn$alpha
# Initialize MKN language mkn
mkn <- mknInit(mkn, training, regex)
# Create absolute counts of each nGram
features <- parallelizeTask(mknAbsCount, mkn, training$nGrams)
# Create continuation counts of each nGram
parallelizeTask(mknCKN, mkn, mkn$mOrder)
# Count nGram histories
parallelizeTask(mknHistories, mkn, mkn$mOrder)
# Calculate discounts
discounts <- mknDiscount(mkn)
# Calculate pseudo probability alpha
parallelizeTask(mknAlpha, mkn)
# Compute weighting factor lambda
parallelizeTask(mknLambda, mkn)
# Compute probabilities
parallelizeTask(mknEstimate, mkn)
# Extract lm
#  extractMkn(mkn)
# Publish language mkn
parallelizeTask(mknPublish, mkn, directories)
# Evaluate Model
pp <- mknEvaluate(mkn, test, sents = NULL, directories = directories)
test <- corpora$validation$alpha$processed[[4]]
pp <- mknEvaluate(mkn, test, sents = NULL, directories = directories)
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM0A.mknEvaluate.R')
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM00.mknPipeline.R')
training
test
mkn
regex <- regexPatterns
directories
korpora <- corpora$training
createNGrams(korpora, directories)
source('~/Data Science/Data Science Projects/PredictifyR-1.0/config/initEnvironment.R')
training <- corpora$training$epsilon
test <- corpora$validation$epsilon
mkn <- lm$mkn$epsilon
regex <- regexPatterns
createTestNGrams(directories)
source('~/Data Science/Data Science Projects/PredictifyR-1.0/lab/createTestNGrams.R')
createTestNGrams(directories)
mkn <- mknInit(mkn, training, regex)
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM01.mknInit.R')
mkn <- mknInit(mkn, training, regex)
features <- parallelizeTask(mknAbsCount, mkn, training$nGrams)
parallelizeTask(mknCKN, mkn, mkn$mOrder)
parallelizeTask(mknHistories, mkn, mkn$mOrder)
discounts <- mknDiscount(mkn)
parallelizeTask(mknAlpha, mkn)
parallelizeTask(mknLambda, mkn)
parallelizeTask(mknEstimate, mkn)
parallelizeTask(mknPublish, mkn, directories)
pp <- mknEvaluate(mkn, test, sents = NULL, directories = directories)
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM0A.mknEvaluate.R')
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM0A.mknEvaluate.R')
pp <- mknEvaluate(mkn, test, sents = NULL, directories = directories)
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM0A.mknEvaluate.R')
pp <- mknEvaluate(mkn, test, sents = NULL, directories = directories)
dt <- pp$detail
View(dt)
sum(dt$prob)
load("~/Data Science/Data Science Projects/PredictifyR-1.0/lm/mkn/epsilon/model/mkn-unigrams.Rdata")
load("~/Data Science/Data Science Projects/PredictifyR-1.0/lm/mkn/epsilon/model/mkn-trigrams.Rdata")
load("~/Data Science/Data Science Projects/PredictifyR-1.0/lm/mkn/epsilon/model/mkn-quadgrams.Rdata")
load("~/Data Science/Data Science Projects/PredictifyR-1.0/lm/mkn/epsilon/model/mkn-bigrams.Rdata")
View(mknQuadgrams)
ngram <- dt$quadgram[[1]]
n <- 4
nGramTypes <- list('Quadgram', 'Trigram', 'Bigram', 'Unigram')
model <- loadModel(mkn)
testData <- loadTestData(test, sents)
startTime <- Sys.time()
message(paste("\nEvaluating performance on ", mkn$mDesc, 'at', startTime))
# Reports progress
rptProgress <- function(startTime, document, x) {
elapsed <- round(difftime(Sys.time(), startTime,  units = 'mins'))
elapsed <- as.numeric(elapsed) + 1
rate <- x / elapsed
remaining <- length(document) - x
timeMin <- round(remaining / rate, digits = 1)
timeHrs <- round(timeMin / 60, digits = 1)
message(paste('......',x,'out of',length(document), 'sentences processed in',
elapsed, 'minutes.', timeMin,'minutes remaining (', timeHrs, 'hours)'))
}
# Loads language model
loadModel <- function(mkn) {
message(paste('...loading language model'))
model <- lapply(seq_along(mkn$model), function(x) {
loadObject(mkn$model[[x]])
})
return(model)
}
# Loads test data
loadTestData <- function(test, sents) {
message(paste('...loading test data'))
document <- readFile(test)
if (!(is.null(sents))) {
document <- sampleData(document, numChunks = sents, chunkSize = 1, format = 'v')
}
dfm <- quanteda::dfm(document, what = 'fasterword', remove = bos, ngrams = 1)
testData <- list(
document = document,
sents = length(document),
tokens = sum(ntoken(dfm)),
types = length(featnames(dfm)),
size = object.size(document)
)
return(testData)
}
# Estimates ngram probability
scoreNgram <- function(ngram, n, model, nGramTypes) {
score <- list()
# Check if n-gram exists in training, and obtain probability
prob <- model[[n]][ nGram == ngram][, Pmkn]
# If exact match, return score object
if (length(prob) != 0) {
score$ngram <- ngram
score$prob <- prob
score$type <- nGramTypes[[n]]
score$logProb <- log2(score$prob)
return(score)
# Else if ngram level greater than 1, obtain score from lower order ngram
} else if (n > 1) {
ngram <- paste0(unlist(strsplit(ngram, ' '))[-1], collapse = ' ')
return(scoreNgram(ngram, n-1, model, nGramTypes))
# Else return score for unknown word
} else {
score$prob <- model[[n]][ nGram == unk][, Pmkn]
return(score)
}
}
# Estimates sentence probability
scoreSentence <- function(sentence, mkn, model, nGramTypes) {
tokens <- unlist(quanteda::tokenize(sentence, what = 'fasterword'))
sentScore <- rbindlist(lapply(seq_along(tokens[1:(length(tokens)-3)]), function(x) {
ngram <- paste0(tokens[x:(x+3)], collapse = ' ')
score <- scoreNgram(ngram, mkn$mOrder, model, nGramTypes)
sentScore <- list()
sentScore$quadgram <- ngram
sentScore$ngramType <- score$type
sentScore$prob <- score$prob
sentScore$logProb <- score$logProb
sentScore
}))
return(sentScore)
}
# Estimates probabilities for corpus
scoreCorpus <- function(document, mkn, model, nGramTypes) {
message('...evaluating sentence probabilities')
startTime <- Sys.time()
scores <- rbindlist(lapply(seq_along(document), function(x) {
s <- scoreSentence(document[x], mkn, model, nGramTypes)
if (x %in% c(100, 200, 500, 1000, 5000, 10000, 20000)) {
rptProgress(document, startTime, x)
}
s
}))
return(scores)
}
# Summarize scoring statistics
getStats <- function(mkn, scores) {
counts <- loadObject(mkn$summary)
counts$Exact[1] <- sum(scores[,ngramType == 'Unigram'])
counts$Exact[2] <- sum(scores[,ngramType == 'Bigram'])
counts$Exact[3] <- sum(scores[,ngramType == 'Trigram'])
counts$Exact[4] <- sum(scores[,ngramType == 'Quadgram'])
counts <- counts[, Pct := Exact / sum(Exact) * 100]
return(counts)
}
# Compute perplexity
calcPerplexity <- function(scores) {
N <- length(scores$logProb)
pp <- 2^-(sum(scores$logProb) / N)
return(pp)
}
# Main processing
nGramTypes <- list('Quadgram', 'Trigram', 'Bigram', 'Unigram')
model <- loadModel(mkn)
testData <- loadTestData(test, sents)
sents = NULL
sents <- NULL
startTime <- Sys.time()
message(paste("\nEvaluating performance on ", mkn$mDesc, 'at', startTime))
# Reports progress
rptProgress <- function(startTime, document, x) {
elapsed <- round(difftime(Sys.time(), startTime,  units = 'mins'))
elapsed <- as.numeric(elapsed) + 1
rate <- x / elapsed
remaining <- length(document) - x
timeMin <- round(remaining / rate, digits = 1)
timeHrs <- round(timeMin / 60, digits = 1)
message(paste('......',x,'out of',length(document), 'sentences processed in',
elapsed, 'minutes.', timeMin,'minutes remaining (', timeHrs, 'hours)'))
}
# Loads language model
loadModel <- function(mkn) {
message(paste('...loading language model'))
model <- lapply(seq_along(mkn$model), function(x) {
loadObject(mkn$model[[x]])
})
return(model)
}
# Loads test data
loadTestData <- function(test, sents) {
message(paste('...loading test data'))
document <- readFile(test)
if (!(is.null(sents))) {
document <- sampleData(document, numChunks = sents, chunkSize = 1, format = 'v')
}
dfm <- quanteda::dfm(document, what = 'fasterword', remove = bos, ngrams = 1)
testData <- list(
document = document,
sents = length(document),
tokens = sum(ntoken(dfm)),
types = length(featnames(dfm)),
size = object.size(document)
)
return(testData)
}
# Estimates ngram probability
scoreNgram <- function(ngram, n, model, nGramTypes) {
score <- list()
# Check if n-gram exists in training, and obtain probability
prob <- model[[n]][ nGram == ngram][, Pmkn]
# If exact match, return score object
if (length(prob) != 0) {
score$ngram <- ngram
score$prob <- prob
score$type <- nGramTypes[[n]]
score$logProb <- log2(score$prob)
return(score)
# Else if ngram level greater than 1, obtain score from lower order ngram
} else if (n > 1) {
ngram <- paste0(unlist(strsplit(ngram, ' '))[-1], collapse = ' ')
return(scoreNgram(ngram, n-1, model, nGramTypes))
# Else return score for unknown word
} else {
score$prob <- model[[n]][ nGram == unk][, Pmkn]
return(score)
}
}
# Estimates sentence probability
scoreSentence <- function(sentence, mkn, model, nGramTypes) {
tokens <- unlist(quanteda::tokenize(sentence, what = 'fasterword'))
sentScore <- rbindlist(lapply(seq_along(tokens[1:(length(tokens)-3)]), function(x) {
ngram <- paste0(tokens[x:(x+3)], collapse = ' ')
score <- scoreNgram(ngram, mkn$mOrder, model, nGramTypes)
sentScore <- list()
sentScore$quadgram <- ngram
sentScore$ngramType <- score$type
sentScore$prob <- score$prob
sentScore$logProb <- score$logProb
sentScore
}))
return(sentScore)
}
# Estimates probabilities for corpus
scoreCorpus <- function(document, mkn, model, nGramTypes) {
message('...evaluating sentence probabilities')
startTime <- Sys.time()
scores <- rbindlist(lapply(seq_along(document), function(x) {
s <- scoreSentence(document[x], mkn, model, nGramTypes)
if (x %in% c(100, 200, 500, 1000, 5000, 10000, 20000)) {
rptProgress(document, startTime, x)
}
s
}))
return(scores)
}
# Summarize scoring statistics
getStats <- function(mkn, scores) {
counts <- loadObject(mkn$summary)
counts$Exact[1] <- sum(scores[,ngramType == 'Unigram'])
counts$Exact[2] <- sum(scores[,ngramType == 'Bigram'])
counts$Exact[3] <- sum(scores[,ngramType == 'Trigram'])
counts$Exact[4] <- sum(scores[,ngramType == 'Quadgram'])
counts <- counts[, Pct := Exact / sum(Exact) * 100]
return(counts)
}
# Compute perplexity
calcPerplexity <- function(scores) {
N <- length(scores$logProb)
pp <- 2^-(sum(scores$logProb) / N)
return(pp)
}
# Main processing
nGramTypes <- list('Quadgram', 'Trigram', 'Bigram', 'Unigram')
model <- loadModel(mkn)
testData <- loadTestData(test, sents)
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM0A.mknEvaluate.R')
model <- loadModel(mkn)
testData <- loadTestData(test, sents)
loadTestData <- function(test, sents) {
message(paste('...loading test data'))
document <- readFile(test)
if (!(is.null(sents))) {
document <- sampleData(document, numChunks = sents, chunkSize = 1, format = 'v')
}
dfm <- quanteda::dfm(document, what = 'fasterword', ngrams = 1)
testData <- list(
document = document,
sents = length(document),
tokens = sum(ntoken(dfm)),
types = length(featnames(dfm)),
size = object.size(document)
)
return(testData)
}
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM0A.mknEvaluate.R')
# Loads test data
loadTestData <- function(test, sents) {
message(paste('...loading test data'))
document <- readFile(test)
if (!(is.null(sents))) {
document <- sampleData(document, numChunks = sents, chunkSize = 1, format = 'v')
}
dfm <- quanteda::dfm(document, what = 'fasterword', remove = '<s>', ngrams = 1)
testData <- list(
document = document,
sents = length(document),
tokens = sum(ntoken(dfm)),
types = length(featnames(dfm)),
size = object.size(document)
)
return(testData)
}
model <- loadModel(mkn)
testData <- loadTestData(test, sents)
prob <- model[[n]][ nGram == ngram][, Pmkn]
length(prob)
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM0A.mknEvaluate.R')
pp <- mknEvaluate(mkn, test, sents = NULL, directories = directories)
dt <- pp$detail
View(dt)
prob <- model[[n]][ nGram == ngram][, Pmkn]
nGramTypes[[4]]
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM0A.mknEvaluate.R')
pp <- mknEvaluate(mkn, test, sents = NULL, directories = directories)
dt <- pp$detail
View(dt)
1/5*sum(dt$logProb)
=-1/5 * log(sum(dt$logProb))
-1/5 * log(sum(dt$logProb))
-1/5 * log2(sum(dt$prob))
scores <- scoreCorpus(testData$document, mkn, model, nGramTypes)
length(scores$logProb)
N <- length(scores$logProb)
pp <- 2^-(log2(sum(scores$prob)) / N)
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM0A.mknEvaluate.R')
pp <- mknEvaluate(mkn, test, sents = NULL, directories = directories)
pp <- 2^-(log2(sum(scores$logProb)) / N)
pp <- 2^-(sum(scores$logProb)) / N
View(scores)
pp <- 2^-(1/N)*(sum(scores$logProb))
pp <- mknEvaluate(mkn, test, sents = NULL, directories = directories)
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM0A.mknEvaluate.R')
# Compute perplexity
calcPerplexity <- function(scores) {
N <- length(scores$logProb)
pp <- 2^-1/N * (sum(scores$logProb))
return(pp)
}
pp <- mknEvaluate(mkn, test, sents = NULL, directories = directories)
exp(sum(dt$logProb))
calcPerplexity <- function(scores) {
N <- length(scores$logProb)
pp <- 2^-(1/N) * (sum(scores$logProb))
return(pp)
}
pp <- mknEvaluate(mkn, test, sents = NULL, directories = directories)
calcPerplexity <- function(scores) {
N <- length(scores$logProb)
pp <- 2^((-1/N) * (sum(scores$logProb)))
return(pp)
}
pp <- mknEvaluate(mkn, test, sents = NULL, directories = directories)
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM0A.mknEvaluate.R')
pp <- mknEvaluate(mkn, test, sents = NULL, directories = directories)
training <- corpora$training$alpha
test <- corpora$test$alpha
mkn <- lm$mkn$alpha
mkn <- mknInit(mkn, training, regex)
# Create absolute counts of each nGram
features <- parallelizeTask(mknAbsCount, mkn, training$nGrams)
# Create continuation counts of each nGram
parallelizeTask(mknCKN, mkn, mkn$mOrder)
# Count nGram histories
parallelizeTask(mknHistories, mkn, mkn$mOrder)
# Calculate discounts
discounts <- mknDiscount(mkn)
# Calculate pseudo probability alpha
parallelizeTask(mknAlpha, mkn)
# Compute weighting factor lambda
parallelizeTask(mknLambda, mkn)
# Compute probabilities
parallelizeTask(mknEstimate, mkn)
# Extract lm
# extractMkn(mkn)
# Publish language mkn
parallelizeTask(mknPublish, mkn, directories)
# Evaluate Model
pp <- mknEvaluate(mkn, test, sents = NULL, directories = directories)
pp <- mknEvaluate(mkn, test, sents = 1000, directories = directories)
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM0A.mknEvaluate.R')
pp <- mknEvaluate(mkn, test, sents = 1000, directories = directories)
test$fileName
filePath <- test$documents[[4]]
filePath <- test$processed[[4]]
document <- readFile(filePath)
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM0A.mknEvaluate.R')
pp <- mknEvaluate(mkn, test, sents = 1000, directories = directories)
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM0A.mknEvaluate.R')
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM0A.mknEvaluate.R')
pp <- mknEvaluate(mkn, test, sents = 1000, directories = directories)
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM00.mknPipeline.R')
pp <- mknEvaluate(mkn, test, sents = 2000, directories = directories)
source('~/Data Science/Data Science Projects/PredictifyR-1.0/config/initEnvironment.R')
pp <- mknEvaluate(mkn, test, sents = 2000, directories = directories)
View(pp)
dt <- pp$detail
View(dt)
View(dt)
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM00.mknPipeline.R')
pp <- mknEvaluate(mkn, test, sents = 1, directories = directories)
dt <- pp$detail
View(dt)
sum(dt$logProb)
extractMkn(mkn)
source('~/Data Science/Data Science Projects/PredictifyR-1.0/lab/extractMkn.R')
extractMkn(mkn)
load("~/Data Science/Data Science Projects/PredictifyR-1.0/lm/mkn/alpha/mkn-discounts.Rdata")
View(mknDiscounts)
pp <- mknEvaluate(mkn, test, sents = 3000, directories = directories)
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM00.mknPipeline.R')
pp <- mknEvaluate(mkn, test, sents = 1000, directories = directories)
parallelizeTask(mknAlpha, mkn)
source('~/Data Science/Data Science Projects/PredictifyR-1.0/config/initEnvironment.R')
pp <- mknEvaluate(mkn, test, sents = 1000, directories = directories)
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM00.mknPipeline.R')
