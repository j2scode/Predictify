mkn$counts[[x-1]]$data <- lower
saveObject(mkn$counts[[x-1]])
}
# Clear all NA values
for (i in seq_along(current)) set(current, i=which(is.na(counts[[i]])), j=i, value=0)
# Save counts
mkn$counts[[x]]$data <- current
saveObject(mkn$counts[[x]])
# Summarize counts
s <- list()
s$nGram <- mkn$counts[[x]]$fileDesc
s$Count <- nfeature(currentNGram)
s
x <- 2
# Load N-grams and list the nGrams to keep
current <- loadObject(mkn$counts[[x]])
# Get N-Gram counts from N-Gram
currentNGram <- loadObject(nGrams[[x]])
counts <- data.table(nGram = featnames(currentNGram),
count = colSums(currentNGram),
key = 'nGram')
# Merge with counts table
current <- merge(current, counts, by='nGram', all.x = TRUE)
# Add in BOS tag counts for highest order context counts(kluge)
if (x == mkn$mOrder) {
bosGram <- paste0(rep("BOS", x), collapse = ' ')
bosCounts <- sum(current[context == bosGram, counts])
lower <- loadObject(mkn$counts[[x-1]])
lower[nGram == bosGram, count := bosCounts]
mkn$counts[[x-1]]$data <- lower
saveObject(mkn$counts[[x-1]])
}
# Clear all NA values
for (i in seq_along(current)) set(current, i=which(is.na(counts[[i]])), j=i, value=0)
# Save counts
mkn$counts[[x]]$data <- current
saveObject(mkn$counts[[x]])
# Summarize counts
s <- list()
s$nGram <- mkn$counts[[x]]$fileDesc
s$Count <- nfeature(currentNGram)
s
x <- 3
current <- loadObject(mkn$counts[[x]])
# Get N-Gram counts from N-Gram
currentNGram <- loadObject(nGrams[[x]])
counts <- data.table(nGram = featnames(currentNGram),
count = colSums(currentNGram),
key = 'nGram')
# Merge with counts table
current <- merge(current, counts, by='nGram', all.x = TRUE)
# Add in BOS tag counts for highest order context counts(kluge)
if (x == mkn$mOrder) {
bosGram <- paste0(rep("BOS", x), collapse = ' ')
bosCounts <- sum(current[context == bosGram, counts])
lower <- loadObject(mkn$counts[[x-1]])
lower[nGram == bosGram, count := bosCounts]
mkn$counts[[x-1]]$data <- lower
saveObject(mkn$counts[[x-1]])
}
# Clear all NA values
for (i in seq_along(current)) set(current, i=which(is.na(current[[i]])), j=i, value=0)
# Save counts
mkn$counts[[x]]$data <- current
saveObject(mkn$counts[[x]])
# Summarize counts
s <- list()
s$nGram <- mkn$counts[[x]]$fileDesc
s$Count <- nfeature(currentNGram)
x <- 4
current <- loadObject(mkn$counts[[x]])
# Get N-Gram counts from N-Gram
currentNGram <- loadObject(nGrams[[x]])
counts <- data.table(nGram = featnames(currentNGram),
count = colSums(currentNGram),
key = 'nGram')
# Merge with counts table
current <- merge(current, counts, by='nGram', all.x = TRUE)
# Add in BOS tag counts for highest order context counts(kluge)
if (x == mkn$mOrder) {
bosGram <- paste0(rep("BOS", x), collapse = ' ')
bosCounts <- sum(current[context == bosGram, counts])
lower <- loadObject(mkn$counts[[x-1]])
lower[nGram == bosGram, count := bosCounts]
mkn$counts[[x-1]]$data <- lower
saveObject(mkn$counts[[x-1]])
}
# Clear all NA values
for (i in seq_along(current)) set(current, i=which(is.na(current[[i]])), j=i, value=0)
# Save counts
mkn$counts[[x]]$data <- current
saveObject(mkn$counts[[x]])
# Summarize counts
s <- list()
s$nGram <- mkn$counts[[x]]$fileDesc
s$Count <- nfeature(currentNGram)
bosGram <- paste0(rep("BOS", x), collapse = ' ')
bosCounts <- sum(current[context == bosGram, count])
lower <- loadObject(mkn$counts[[x-1]])
lower[nGram == bosGram, count := bosCounts]
bosCounts <- sum(current[context == bosGram, count])
current[context == bosGram, count]
current[context == bosGram]
current[,context == bosGram]
bosCounts <- sum(current[,context == bosGram, count])
bosGram <- paste0(rep("BOS", x-1), collapse = ' ')
bosCounts <- sum(current[,context == bosGram, count])
lower[nGram == bosGram, count := bosCounts]
View(lower)
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM02.mknAbsCount.R')
mkn <- lm$mkn$alpha
source('~/Data Science/Data Science Projects/PredictifyR-1.0/config/initEnvironment.R')
mkn <- lm$mkn$alpha
model <- lapply(seq_along(mkn$counts), function(x) {
loadObject(mkn$counts[[x]])
})
n1 <- model[[1]]
n2 <- model[[2]]
n3 <- model[[3]]
n4 <- model[[4]]
discounts <- loadObject(mkn$discounts)
summary <- loadObject(mkn$summary)
View(n4)
View(n3)
x <- 4
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM01.mknInit.R')
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM01.mknInit.R')
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM01.mknInit.R')
x <- 1
message(paste('...calculating counts for', nGrams[[x]]$fileDesc))
# Load N-grams and list the nGrams to keep
current <- loadObject(mkn$counts[[x]])
# Get N-Gram counts from N-Gram
currentNGram <- loadObject(nGrams[[x]])
counts <- data.table(nGram = featnames(currentNGram),
count = colSums(currentNGram),
key = 'nGram')
# Merge with counts table
current <- merge(current, counts, by='nGram', all.x = TRUE)
# Add in BOS tag counts for highest order context counts(kluge)
if (x == mkn$mOrder) {
bosGram <- paste0(rep("BOS", x-1), collapse = ' ')x
bosCounts <- sum(current[,context == bosGram, count])
lower <- loadObject(mkn$counts[[x-1]])
lower[nGram == bosGram, count := bosCounts]
mkn$counts[[x-1]]$data <- lower
saveObject(mkn$counts[[x-1]])
}
# Clear all NA values
for (i in seq_along(current)) set(current, i=which(is.na(current[[i]])), j=i, value=0)
# Save counts
mkn$counts[[x]]$data <- current
saveObject(mkn$counts[[x]])
# Summarize counts
s <- list()
s$nGram <- mkn$counts[[x]]$fileDesc
s$Count <- nfeature(currentNGram)
s
nGrams <- corpora$training$alpha$nGrams
# Load N-grams and list the nGrams to keep
current <- loadObject(mkn$counts[[x]])
# Get N-Gram counts from N-Gram
currentNGram <- loadObject(nGrams[[x]])
counts <- data.table(nGram = featnames(currentNGram),
count = colSums(currentNGram),
key = 'nGram')
# Merge with counts table
current <- merge(current, counts, by='nGram', all.x = TRUE)
# Add in BOS tag counts for highest order context counts(kluge)
if (x == mkn$mOrder) {
bosGram <- paste0(rep("BOS", x-1), collapse = ' ')x
bosCounts <- sum(current[,context == bosGram, count])
lower <- loadObject(mkn$counts[[x-1]])
lower[nGram == bosGram, count := bosCounts]
mkn$counts[[x-1]]$data <- lower
saveObject(mkn$counts[[x-1]])
}
# Clear all NA values
for (i in seq_along(current)) set(current, i=which(is.na(current[[i]])), j=i, value=0)
# Save counts
mkn$counts[[x]]$data <- current
saveObject(mkn$counts[[x]])
# Summarize counts
s <- list()
s$nGram <- mkn$counts[[x]]$fileDesc
s$Count <- nfeature(currentNGram)
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM01.mknInit.R')
x <- 1
# Load N-grams and list the nGrams to keep
current <- loadObject(mkn$counts[[x]])
# Get N-Gram counts from N-Gram
currentNGram <- loadObject(nGrams[[x]])
counts <- data.table(nGram = featnames(currentNGram),
count = colSums(currentNGram),
key = 'nGram')
# Merge with counts table
current <- merge(current, counts, by='nGram', all.x = TRUE)
# Add in BOS tag counts for highest order context counts(kluge)
if (x == mkn$mOrder) {
bosGram <- paste0(rep("BOS", x-1), collapse = ' ')
bosCounts <- sum(current[,context == bosGram, count])
lower <- loadObject(mkn$counts[[x-1]])
lower[nGram == bosGram, count := bosCounts]
mkn$counts[[x-1]]$data <- lower
saveObject(mkn$counts[[x-1]])
}
# Clear all NA values
for (i in seq_along(current)) set(current, i=which(is.na(current[[i]])), j=i, value=0)
# Save counts
mkn$counts[[x]]$data <- current
saveObject(mkn$counts[[x]])
# Summarize counts
s <- list()
s$nGram <- mkn$counts[[x]]$fileDesc
s$Count <- nfeature(currentNGram)
x <- 2
# Load N-grams and list the nGrams to keep
current <- loadObject(mkn$counts[[x]])
# Get N-Gram counts from N-Gram
currentNGram <- loadObject(nGrams[[x]])
counts <- data.table(nGram = featnames(currentNGram),
count = colSums(currentNGram),
key = 'nGram')
# Merge with counts table
current <- merge(current, counts, by='nGram', all.x = TRUE)
# Add in BOS tag counts for highest order context counts(kluge)
if (x == mkn$mOrder) {
bosGram <- paste0(rep("BOS", x-1), collapse = ' ')
bosCounts <- sum(current[,context == bosGram, count])
lower <- loadObject(mkn$counts[[x-1]])
lower[nGram == bosGram, count := bosCounts]
mkn$counts[[x-1]]$data <- lower
saveObject(mkn$counts[[x-1]])
}
# Clear all NA values
for (i in seq_along(current)) set(current, i=which(is.na(current[[i]])), j=i, value=0)
# Save counts
mkn$counts[[x]]$data <- current
saveObject(mkn$counts[[x]])
# Summarize counts
s <- list()
s$nGram <- mkn$counts[[x]]$fileDesc
s$Count <- nfeature(currentNGram)
x <- 3
# Load N-grams and list the nGrams to keep
current <- loadObject(mkn$counts[[x]])
# Get N-Gram counts from N-Gram
currentNGram <- loadObject(nGrams[[x]])
counts <- data.table(nGram = featnames(currentNGram),
count = colSums(currentNGram),
key = 'nGram')
# Merge with counts table
current <- merge(current, counts, by='nGram', all.x = TRUE)
# Add in BOS tag counts for highest order context counts(kluge)
if (x == mkn$mOrder) {
bosGram <- paste0(rep("BOS", x-1), collapse = ' ')
bosCounts <- sum(current[,context == bosGram, count])
lower <- loadObject(mkn$counts[[x-1]])
lower[nGram == bosGram, count := bosCounts]
mkn$counts[[x-1]]$data <- lower
saveObject(mkn$counts[[x-1]])
}
# Clear all NA values
for (i in seq_along(current)) set(current, i=which(is.na(current[[i]])), j=i, value=0)
# Save counts
mkn$counts[[x]]$data <- current
saveObject(mkn$counts[[x]])
# Summarize counts
s <- list()
s$nGram <- mkn$counts[[x]]$fileDesc
s$Count <- nfeature(currentNGram)
x <- 4
current <- loadObject(mkn$counts[[x]])
currentNGram <- loadObject(nGrams[[x]])
counts <- data.table(nGram = featnames(currentNGram),
count = colSums(currentNGram),
key = 'nGram')
# Merge with counts table
current <- merge(current, counts, by='nGram', all.x = TRUE)
bosGram <- paste0(rep("BOS", x-1), collapse = ' ')
lower <- loadObject(mkn$counts[[x-1]])
bosCounts <- sum(current[,context == bosGram, count], na.rm = TRUE)
lower <- loadObject(mkn$counts[[x-1]])
View(lower)
lower[nGram == bosGram, count := bosCounts]
View(lower)
mkn$counts[[x-1]]$data <- lower
saveObject(mkn$counts[[x-1]])
n3 <- model[[3]]
n3 <- loadObject(mkn$counts[[3]])
x <- 4
# Add in BOS tag counts for highest order context counts(kluge)
if (x == mkn$mOrder) {
bosGram <- paste0(rep("BOS", x-1), collapse = ' ')
setkey(current, context)
bosCounts <- sum(current[,context == bosGram, count], na.rm = TRUE)
lower <- loadObject(mkn$counts[[x-1]])
lower[nGram == bosGram, count := bosCounts]
mkn$counts[[x-1]]$data <- lower
saveObject(mkn$counts[[x-1]])
}
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM02.mknAbsCount.R')
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM01.mknInit.R')
n1 <- loadObject(mkn$counts[[1]])
n2 <- loadObject(mkn$counts[[2]])
n3 <- loadObject(mkn$counts[[3]])
n4 <- loadObject(mkn$counts[[4]])
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM10.mknPerplexity.R')
mkn <- lm$mkn$gamma
nGrams <- corpora$training$gamma$nGrams
regex <- regexPatterns
x <- 1
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM01.mknInit.R')
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM01.mknInit.R')
x <- 1
# Load N-grams and list the nGrams to keep
current <- loadObject(mkn$counts[[x]])
# Get N-Gram counts from N-Gram
currentNGram <- loadObject(nGrams[[x]])
counts <- data.table(nGram = featnames(currentNGram),
count = colSums(currentNGram),
key = 'nGram')
# Merge with counts table
current <- merge(current, counts, by='nGram', all.x = TRUE)
# Add in BOS tag counts for highest order context counts(kluge)
if (x == mkn$mOrder) {
bosGram <- paste0(rep("BOS", x-1), collapse = ' ')
setkey(current, context)
bosCounts <- sum(current[,context == bosGram, count], na.rm = TRUE)
lower <- loadObject(mkn$counts[[x-1]])
lower[nGram == bosGram, count := bosCounts]
mkn$counts[[x-1]]$data <- lower
saveObject(mkn$counts[[x-1]])
}
# Clear all NA values
for (i in seq_along(current)) set(current, i=which(is.na(current[[i]])), j=i, value=0)
# Save counts
mkn$counts[[x]]$data <- current
saveObject(mkn$counts[[x]])
# Summarize counts
s <- list()
s$nGram <- mkn$counts[[x]]$fileDesc
s$Count <- nfeature(currentNGram)
x <- 2
# Load N-grams and list the nGrams to keep
current <- loadObject(mkn$counts[[x]])
# Get N-Gram counts from N-Gram
currentNGram <- loadObject(nGrams[[x]])
counts <- data.table(nGram = featnames(currentNGram),
count = colSums(currentNGram),
key = 'nGram')
# Merge with counts table
current <- merge(current, counts, by='nGram', all.x = TRUE)
# Add in BOS tag counts for highest order context counts(kluge)
if (x == mkn$mOrder) {
bosGram <- paste0(rep("BOS", x-1), collapse = ' ')
setkey(current, context)
bosCounts <- sum(current[,context == bosGram, count], na.rm = TRUE)
lower <- loadObject(mkn$counts[[x-1]])
lower[nGram == bosGram, count := bosCounts]
mkn$counts[[x-1]]$data <- lower
saveObject(mkn$counts[[x-1]])
}
# Clear all NA values
for (i in seq_along(current)) set(current, i=which(is.na(current[[i]])), j=i, value=0)
# Save counts
mkn$counts[[x]]$data <- current
saveObject(mkn$counts[[x]])
# Summarize counts
s <- list()
s$nGram <- mkn$counts[[x]]$fileDesc
s$Count <- nfeature(currentNGram)
x <-3
# Load N-grams and list the nGrams to keep
current <- loadObject(mkn$counts[[x]])
# Get N-Gram counts from N-Gram
currentNGram <- loadObject(nGrams[[x]])
counts <- data.table(nGram = featnames(currentNGram),
count = colSums(currentNGram),
key = 'nGram')
# Merge with counts table
current <- merge(current, counts, by='nGram', all.x = TRUE)
# Add in BOS tag counts for highest order context counts(kluge)
if (x == mkn$mOrder) {
bosGram <- paste0(rep("BOS", x-1), collapse = ' ')
setkey(current, context)
bosCounts <- sum(current[,context == bosGram, count], na.rm = TRUE)
lower <- loadObject(mkn$counts[[x-1]])
lower[nGram == bosGram, count := bosCounts]
mkn$counts[[x-1]]$data <- lower
saveObject(mkn$counts[[x-1]])
}
# Clear all NA values
for (i in seq_along(current)) set(current, i=which(is.na(current[[i]])), j=i, value=0)
# Save counts
mkn$counts[[x]]$data <- current
saveObject(mkn$counts[[x]])
# Summarize counts
s <- list()
s$nGram <- mkn$counts[[x]]$fileDesc
s$Count <- nfeature(currentNGram)
x <- 4
current <- loadObject(mkn$counts[[x]])
currentNGram <- loadObject(nGrams[[x]])
counts <- data.table(nGram = featnames(currentNGram),
count = colSums(currentNGram),
key = 'nGram')
setkey(current, nGram)
current <- merge(current, counts, by='nGram', all.x = TRUE)
bosGram <- paste0(rep("BOS", x-1), collapse = ' ')
setkey(current, context)
bosCounts <- sum(current[,context == bosGram, count], na.rm = TRUE)
memory.limit(20000)
bosCounts <- sum(current[,context == bosGram, count], na.rm = TRUE)
temp <- current[, c('context', 'count')]
bosCounts <- sum(temp[,context == bosGram, count], na.rm = TRUE)
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM02.mknAbsCount.R')
load("~/Data Science/Data Science Projects/PredictifyR-1.0/analysis/model-corpora-descriptive-statistics_20170524_113627.Rdata")
View(corporaSummary)
mkn <- lm$mkn$alpha
n1 <- loadObject(mkn$counts[[1]])
n2 <- loadObject(mkn$counts[[2]])
n3 <- loadObject(mkn$counts[[3]])
n4 <- loadObject(mkn$counts[[4]])
n4Bos <- n4[context == 'BOS BOS BOS']
sum(n4Box[count])
sum(n4Bos[count])
sum(n4Bos[,count])
x
bosGram <- paste0(rep("BOS", x-1), collapse = ' ')
setkey(current, context)
temp <- current[context == bosGram, c('context', 'count')]
bosCounts <- sum(temp[,count], na.rm = TRUE)
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM02.mknAbsCount.R')
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM10.mknPerplexity.R')
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM08.mknEstimate.R')
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM08.mknEstimate.R')
x <- 1
mkn <- lm$mkn$alpha
startTime <- Sys.time()
message(paste("\nPublishing", mkn$mDesc, 'at', startTime))
counts <- loadObject(mkn$counts[[x]])
model <- counts[, c('nGram', 'Pmkn')]
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM09.mknPublish.R')
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM09.mknPublish.R')
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM09.mknPublish.R')
Q
Q
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM09.mknPublish.R')
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM09.mknPublish.R')
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM09.mknPublish.R')
source('~/Data Science/Data Science Projects/PredictifyR-1.0/config/initEnvironment.R')
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM09.mknPublish.R')
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM09.mknPublish.R')
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM09.mknPublish.R')
load("~/Data Science/Data Science Projects/PredictifyR-1.0/analysis/MKN-publish-MKNAlpha_20170529_115917.Rdata")
View(modelSize)
x <- 1
mkn$model[[x]]$fileDesc
mkn <- lm$mkn$alpha
mkn$model[[x]]$fileDesc
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM09.mknPublish.R')
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM00.mknPipeline.R')
load("~/Data Science/Data Science Projects/PredictifyR-1.0/analysis/MKN-publish-MKNBeta_20170529_120954.Rdata")
View(modelSize)
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM09.mknPublish.R')
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM09.mknPublish.R')
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM09.mknPublish.R')
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM09.mknPublish.R')
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM09.mknPublish.R')
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM09.mknPublish.R')
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM11.mknPerplexity.R')
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM11.mknPerplexity.R')
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM11.mknPerplexity.R')
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM11.mknPerplexity.R')
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM11.mknPerplexity.R')
load("~/Data Science/Data Science Projects/PredictifyR-1.0/analysis/MKN-perplexity-MKNAlpha_20170529_125948.Rdata")
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM11.mknPerplexity.R')
load("~/Data Science/Data Science Projects/PredictifyR-1.0/analysis/MKN-perplexity-MKNBeta_20170529_130303.Rdata")
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM11.mknPerplexity.R')
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM11.mknPerplexity.R')
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM11.mknPerplexity.R')
load("~/Data Science/Data Science Projects/PredictifyR-1.0/analysis/MKN-perplexity-MKNDelta_20170529_132354.Rdata")
source('~/Data Science/Data Science Projects/PredictifyR-1.0/src/LM11.mknPerplexity.R')
source('~/Data Science/Data Science Projects/PredictifyR-1.0/config/initEnvironment.R')
mkn <- lm$mkn$alpha
training <- corpora$training$alpha
test <- corpora$validation$alpha
sents = 1000
message('...loading training data')
train <- readFile(training$processed[[mkn$mOrder]])
df <- quanteda::dfm(train, tolower = FALSE, remove = 'BOS')
V <- length(featnames(df))
trainTokens <- sum(ntoken(df))
message(paste('...loading language model'))
model <- lapply(seq_along(mkn$model), function(x) {
loadObject(mkn$model[[x]])
})
message(paste('...loading test data'))
document <- readFile(test$processed[[mkn$mOrder]])
if (!(is.null(sents))) {
document <- sampleData(document, numChunks = sents, chunkSize = 1, format = 'v')
}
# Compute number of sentences and tokens w/o 'BOS'
M <- length(document) # M = number of sentences
n1 <- model[[1]]
n2 <- model[[2]]
n3 <- model[[3]]
n4 <- model[[4]]
View(n3)
load("~/Data Science/Data Science Projects/PredictifyR-1.0/analysis/MKN-perplexity-MKNAlpha_20170529_125948.Rdata")
load("~/Data Science/Data Science Projects/PredictifyR-1.0/analysis/MKN-perplexity-MKNDelta_20170529_132354.Rdata")
